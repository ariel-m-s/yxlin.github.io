<!DOCTYPE html>

<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">

		<!-- Begin Jekyll SEO tag v2.4.0 -->
<title>One Participant | Cognitive Models</title>
<meta name="generator" content="Jekyll v3.7.2" />
<meta property="og:title" content="One Participant" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Fixed-effects models refer to a scenario that each participant has independent parameter generating mechanism. This is relative to another scenario that all participants are under one common mechanism of parameter generation. The latter scenario sometimes is dubbed random effects, hierarchical or multi-level models, although each term has slightly different meanings." />
<meta property="og:description" content="Fixed-effects models refer to a scenario that each participant has independent parameter generating mechanism. This is relative to another scenario that all participants are under one common mechanism of parameter generation. The latter scenario sometimes is dubbed random effects, hierarchical or multi-level models, although each term has slightly different meanings." />
<link rel="canonical" href="http://localhost:4000/fixed-effect-model/one_participant/" />
<meta property="og:url" content="http://localhost:4000/fixed-effect-model/one_participant/" />
<meta property="og:site_name" content="Cognitive Models" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-03-14T06:58:28+00:00" />
<script type="application/ld+json">
{"@type":"Article","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"http://localhost:4000/siteicon.png"}},"url":"http://localhost:4000/fixed-effect-model/one_participant/","headline":"One Participant","dateModified":"2019-03-14T06:58:28+00:00","datePublished":"2019-03-14T06:58:28+00:00","description":"Fixed-effects models refer to a scenario that each participant has independent parameter generating mechanism. This is relative to another scenario that all participants are under one common mechanism of parameter generation. The latter scenario sometimes is dubbed random effects, hierarchical or multi-level models, although each term has slightly different meanings.","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

		<link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Cognitive Models" />

		<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:400,400italic,700,700italic|Open+Sans:400,400italic,600,600italic,700,700italic|Inconsolata:400,700">
		<link rel="stylesheet" href="/css/main.css">
		<link rel="apple-touch-icon" href="/apple-touch-icon.png">
		<link rel="icon" type="image/png" href="/touch-icon.png" sizes="192x192">
		<link rel="icon" type="image/png" href="/images/favicon.png">

		
	</head>

	<body>
	  <header>
	    <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"></script>
	    
			<h1>
				<a href="/"><img src="/images/emblem.svg" width="40" height="40" alt="Cognitive Models logo"></a>
				Cognitive Models
				<button type="button" class="open-nav" id="open-nav"></button>
			</h1>

			<form action="/search/" method="get">
				<input type="text" name="q" id="search-input" placeholder="Search" autofocus>
				<input type="submit" value="Search" style="display: none;">
			</form>

			<nav >
				<ul>
					<li class="nav-item top-level ">
						
						<a href="/"></a>
					</li>
				</ul>

				<ul>
					
					
						<li class="nav-item top-level ">
							
							<a href="/BUGS/hnormal/">BUGS Examples Volumn 1</a>
							<ul>
								
									<li class="nav-item "><a href="/BUGS/hnormal/">Hierarchical Normal Model</a></li>
								
									<li class="nav-item "><a href="/BUGS/seeds/">Random effect logistic regression</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/approximation/kde/">Likelihood Free Method</a>
							<ul>
								
									<li class="nav-item "><a href="/approximation/kde/">Kernel Density Estimation</a></li>
								
									<li class="nav-item "><a href="/approximation/pda/">Probability Density Approximation</a></li>
								
									<li class="nav-item "><a href="/approximation/ppda/">Parallel Probability Density Approximation</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/basics/model_array/">Modelling Basics</a>
							<ul>
								
									<li class="nav-item "><a href="/basics/model_array/">Model Array</a></li>
								
									<li class="nav-item "><a href="/basics/simulation/">Simulation</a></li>
								
									<li class="nav-item "><a href="/basics/descriptive/">Descriptive Statistics</a></li>
								
									<li class="nav-item "><a href="/basics/summary/">Summary Statistics</a></li>
								
									<li class="nav-item "><a href="/basics/mle/">Maximising Likelihoods</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/bayes-basics/theorem/">Bayesian Basics</a>
							<ul>
								
									<li class="nav-item "><a href="/bayes-basics/theorem/">Bayes' Theorem</a></li>
								
									<li class="nav-item "><a href="/bayes-basics/prior/">Prior Distribution</a></li>
								
									<li class="nav-item "><a href="/bayes-basics/likelihood/">Model Likelihood</a></li>
								
									<li class="nav-item "><a href="/bayes-basics/posterior/">Posterior Distribution</a></li>
								
									<li class="nav-item "><a href="/bayes-basics/diagnosis/">Checking Fitted Models</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/cognitive-model/sdt/">Cognitive Model</a>
							<ul>
								
									<li class="nav-item "><a href="/cognitive-model/sdt/">Signal Detection Model</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/lba/">Linear Ballistic Accumulation Model</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/ddm/">Diffusion Decision Model</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/cddm/">Circular Diffusion Decision Model</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/plba/">PLBA Model</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/pddm/">PDDM</a></li>
								
									<li class="nav-item "><a href="/cognitive-model/lba3/">Three-accumulator LBA Model</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level current">
							
							<a href="/fixed-effect-model/one_participant/">Fixed Effects Model</a>
							<ul>
								
									<li class="nav-item current"><a href="/fixed-effect-model/one_participant/">One Participant</a></li>
								
									<li class="nav-item "><a href="/fixed-effect-model/many_participants/">Multiple Participants</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/mcmc/mcmc/">Modern Bayesian Statistics</a>
							<ul>
								
									<li class="nav-item "><a href="/mcmc/mcmc/">Markov Chain Monte Carlo</a></li>
								
									<li class="nav-item "><a href="/mcmc/rwm/">Random Walk Metropolis</a></li>
								
									<li class="nav-item "><a href="/mcmc/hastings/">Metropolis-Hastings</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/random-effect-model/hlba/">Hierarchical Model</a>
							<ul>
								
									<li class="nav-item "><a href="/random-effect-model/hlba/">Hierarchical LBA Model</a></li>
								
									<li class="nav-item "><a href="/random-effect-model/hddm/">Hierarchical DDM</a></li>
								
									<li class="nav-item "><a href="/random-effect-model/hcddm/">Hierarchical Circular DDM</a></li>
								
									<li class="nav-item "><a href="/random-effect-model/shooting-decision1/">Shooting Decision Model - Recovery Study</a></li>
								
									<li class="nav-item "><a href="/random-effect-model/shooting-decision2/">Shooting Decision Model - Empirical Data</a></li>
								
							</ul>
						</li>
					
						<li class="nav-item top-level ">
							
							<a href="/sampling/genetic/">Sampling Techniques</a>
							<ul>
								
									<li class="nav-item "><a href="/sampling/genetic/">Population-based Monte Carlo</a></li>
								
									<li class="nav-item "><a href="/sampling/crossover/">Crossover</a></li>
								
									<li class="nav-item "><a href="/sampling/migration/">Migration</a></li>
								
									<li class="nav-item "><a href="/sampling/mutation/">Mutation</a></li>
								
									<li class="nav-item "><a href="/sampling/demc/">Differential Evolution Monte Carlo</a></li>
								
									<li class="nav-item "><a href="/sampling/demcmc/">Differential Evolution Markov Chain Monte Carlo</a></li>
								
									<li class="nav-item "><a href="/sampling/dgmc/">Distributed Genetic Monte Carlo</a></li>
								
							</ul>
						</li>
					
				</ul>

				<ul>
					<li class="nav-item top-level ">
						
						<a href="/changelog/">Change Log</a>
					</li>
				</ul>
			</nav>
		</header>

		<section class="main">
			<div class="page-header">
				<h2>Fixed Effects Model</h2>
				<h3>One Participant</h3>
			</div>
			<article class="content">
				<p>Fixed-effects models refer to a scenario that each participant
has independent parameter generating mechanism. This is relative to
another scenario that all participants are under one common mechanism
of parameter generation.  The latter scenario sometimes is dubbed
random effects, hierarchical or multi-level models, although each term 
has slightly different meanings.</p>

<p>In this tutorial, I illustrate the method of conducting Bayesian MCMC sampling
in the fixed-effects scenario. Given a data set containing (1) response times
and (2) response choices, one aim is to estimate the parameters that
generate the response latency and choices. The sampling technique based on
Bayesian MCMC helps to draw (posterior) samples from the probability
distribution generating the data, even we do not know the exact
mathematical form of this particular probability distribution.</p>

<p>For example, we know the <a href="https://en.wikipedia.org/wiki/Gaussian_function">Gaussian (normal distribution) function</a>.
If we also know the values of its parameters,
mean and standard deviation, we can draw its samples by, for instance,
using R’s <em>rnorm</em> function,</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mu &lt;- 0
sigma &lt;- 1
dat &lt;- rnorm(1e3, mu, sigma)
</code></pre></div></div>

<p><img src="/images/fixed-effect-model/Gaussian.png" alt="Gaussian" /></p>

<p>The usual situation is that we would collect data (<em>dat</em>) by inviting
participants to visit our lab, having them perform some sort of
cognitive tasks and in the meantime recording their RTs and choices. 
In this more realistic situation, we need to estimate <em>mu</em>
and <em>sigma</em>.  Of course, this presumes that if we 
assume that the Gaussian is the model accounting for participants’
particular behaviours when they are doing the cognitive tasks.</p>

<p>More often, we would use a RT model, for example diffusion decision model
(DDM) (Ratcliff &amp; McKoon, 2008)<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup>. As usual, I firstly set up a model
object. The <em>type</em> = <strong>“rd”</strong>, refers to Ratcliff’s diffusion model.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">model</span> <span class="p">&lt;-</span> <span class="n">BuildModel</span><span class="p">(</span>
  <span class="n">p</span><span class="p">.</span><span class="n">map</span>     <span class="p">=</span> <span class="k">list</span><span class="p">(</span><span class="n">a</span> <span class="p">=</span> <span class="s2">"1"</span><span class="p">,</span> <span class="n">v</span> <span class="p">=</span> <span class="s2">"1"</span><span class="p">,</span> <span class="n">z</span> <span class="p">=</span> <span class="s2">"1"</span><span class="p">,</span> <span class="n">d</span> <span class="p">=</span> <span class="s2">"1"</span><span class="p">,</span> <span class="n">sz</span> <span class="p">=</span> <span class="s2">"1"</span><span class="p">,</span> <span class="n">sv</span> <span class="p">=</span> <span class="s2">"1"</span><span class="p">,</span>
                   <span class="n">t0</span> <span class="p">=</span> <span class="s2">"1"</span><span class="p">,</span> <span class="n">st0</span> <span class="p">=</span> <span class="s2">"1"</span><span class="p">),</span>
  <span class="n">match</span><span class="p">.</span><span class="n">map</span> <span class="p">=</span> <span class="k">list</span><span class="p">(</span><span class="n">M</span> <span class="p">=</span> <span class="k">list</span><span class="p">(</span><span class="n">s1</span> <span class="p">=</span> <span class="s2">"r1"</span><span class="p">,</span> <span class="n">s2</span> <span class="p">=</span> <span class="s2">"r2"</span><span class="p">)),</span>
  <span class="n">factors</span>   <span class="p">=</span> <span class="k">list</span><span class="p">(</span><span class="n">S</span> <span class="p">=</span> <span class="n">c</span><span class="p">(</span><span class="s2">"s1"</span><span class="p">,</span> <span class="s2">"s2"</span><span class="p">)),</span>
  <span class="n">responses</span> <span class="p">=</span> <span class="n">c</span><span class="p">(</span><span class="s2">"r1"</span><span class="p">,</span> <span class="s2">"r2"</span><span class="p">),</span>
  <span class="n">constants</span> <span class="p">=</span> <span class="n">c</span><span class="p">(</span><span class="n">st0</span> <span class="p">=</span> <span class="m">0</span><span class="p">,</span> <span class="n">d</span> <span class="p">=</span> <span class="m">0</span><span class="p">),</span>
  <span class="n">type</span>      <span class="p">=</span> <span class="s2">"rd"</span><span class="p">)</span>

<span class="n">p</span><span class="p">.</span><span class="n">vector</span> <span class="p">&lt;-</span> <span class="n">c</span><span class="p">(</span><span class="n">a</span> <span class="p">=</span> <span class="m">1</span><span class="p">,</span> <span class="n">v</span> <span class="p">=</span> <span class="m">1.2</span><span class="p">,</span> <span class="n">z</span> <span class="p">=</span> <span class="m">.38</span><span class="p">,</span> <span class="n">sz</span> <span class="p">=</span> <span class="m">.25</span><span class="p">,</span> <span class="n">sv</span> <span class="p">=</span> <span class="m">.2</span><span class="p">,</span> <span class="n">t0</span> <span class="p">=</span> <span class="m">.15</span><span class="p">)</span>
<span class="n">ntrial</span> <span class="p">&lt;-</span> <span class="m">1e2</span>
<span class="n">dat</span> <span class="p">&lt;-</span> <span class="n">simulate</span><span class="p">(</span><span class="k">model</span><span class="p">,</span> <span class="n">nsim</span> <span class="p">=</span> <span class="n">ntrial</span><span class="p">,</span> <span class="n">ps</span> <span class="p">=</span> <span class="n">p</span><span class="p">.</span><span class="n">vector</span><span class="p">)</span>
<span class="n">dmi</span> <span class="p">&lt;-</span> <span class="n">BuildDMI</span><span class="p">(</span><span class="n">dat</span><span class="p">,</span> <span class="k">model</span><span class="p">)</span>
<span class="p">##</span> <span class="n">A</span> <span class="n">tibble</span><span class="p">:</span> <span class="m">200</span> <span class="n">x</span> <span class="m">3</span>     <span class="p">##</span> <span class="n">use</span> <span class="n">dplyr</span><span class="p">::</span><span class="n">tbl_df</span><span class="p">(</span><span class="n">dat</span><span class="p">)</span> <span class="k">to</span> <span class="n">print</span> <span class="n">this</span>
<span class="p">##</span>    <span class="n">S</span>     <span class="n">R</span>        <span class="n">RT</span>
<span class="p">##</span>    <span class="p">&lt;</span><span class="n">fct</span><span class="p">&gt;</span> <span class="p">&lt;</span><span class="n">fct</span><span class="p">&gt;</span> <span class="p">&lt;</span><span class="n">dbl</span><span class="p">&gt;</span>
<span class="p">##</span>  <span class="m">1</span> <span class="n">s1</span>    <span class="n">r1</span>    <span class="m">0.249</span>
<span class="p">##</span>  <span class="m">2</span> <span class="n">s1</span>    <span class="n">r1</span>    <span class="m">0.246</span>
<span class="p">##</span>  <span class="m">3</span> <span class="n">s1</span>    <span class="n">r2</span>    <span class="m">0.262</span>
<span class="p">##</span>  <span class="m">4</span> <span class="n">s1</span>    <span class="n">r1</span>    <span class="m">0.519</span>
<span class="p">##</span>  <span class="m">5</span> <span class="n">s1</span>    <span class="n">r1</span>    <span class="m">0.205</span>
<span class="p">##</span>  <span class="m">6</span> <span class="n">s1</span>    <span class="n">r1</span>    <span class="m">0.177</span>
<span class="p">##</span>  <span class="m">7</span> <span class="n">s1</span>    <span class="n">r1</span>    <span class="m">0.174</span>
<span class="p">##</span>  <span class="m">8</span> <span class="n">s1</span>    <span class="n">r1</span>    <span class="m">0.378</span>
<span class="p">##</span>  <span class="m">9</span> <span class="n">s1</span>    <span class="n">r1</span>    <span class="m">0.197</span>
<span class="p">##</span> <span class="m">10</span> <span class="n">s1</span>    <span class="n">r1</span>    <span class="m">0.224</span>
<span class="p">##</span>  <span class="p">...</span> <span class="k">with</span> <span class="m">190</span> <span class="n">more</span> <span class="n">rows</span>

</code></pre></div></div>

<p>Because the data were simulated from a set of presume true values, <em>p.vector</em>,
I can use them later to verify whether the sampling process appropriately
estimates the parameters. In Bayesian statistics, we also need prior
distributions, so let’s build a set of prior distributions for each
DDM parameters.</p>

<p>A beta distribution with shape1 = 1 and shape2 = 1, equals to a uniform
distribution (<em>beta(1, 1)</em>). This is for the start point, <em>z</em>, its variability
<em>sz</em> and <em>t0</em> parameters. All three are bounded by 0 and 1. Others use
truncated normal distributions bounded by <em>lower</em> and <em>upper</em> arguments.
<em>plot</em> draws the prior distribution, providing a visual check method.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>p.prior  &lt;- BuildPrior(
  dists = c(rep("tnorm", 2), "beta", "beta", "tnorm", "beta"),
  p1    = c(a = 1, v = 0, z = 1, sz = 1, sv = 1, t0 = 1),
  p2    = c(a = 1, v = 2, z = 1, sz = 1, sv = 1, t0 = 1),
  lower = c(0, -5, NA, NA, 0, NA),
  upper = c(5,  5, NA, NA, 5, NA))
plot(p.prior, ps = p.vector)
</code></pre></div></div>

<p><img src="/images/fixed-effect-model/prior.png" alt="prior" /></p>

<p>By default <em>StartNewsamples</em> uses p.prior to randomly draw start
points and 500 MCMC samples.  This step uses a mixture of crossover
and migration operators. The <em>run</em> function by default draw 500
MCMC samples, using only crossover operator. <em>gelman</em> function
report rhat value of 1.06 in this case. A rhat value less than 1.1
is usually considered an indication of chains converged.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>fit0 &lt;- StartNewsamples(dmi, p.prior)
fit  &lt;- run(fit0)
rhat &lt;- gelman(fit, verbose = TRUE)
## Diagnosing a single participant, theta. Rhat = 1.06

</code></pre></div></div>

<p><em>plot</em> by default draws posterior log-likelihood, with the option, <em>start</em>,
to change to a latter start iteration to draw.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>p0 &lt;- plot(fit0)
## p0 &lt;- plot(fit0, start = 101)
p1 &lt;- plot(fit)

png("pll.png", 800, 600)
gridExtra::grid.arrange(p0, p1, ncol = 1)
dev.off()
</code></pre></div></div>

<p><img src="/images/fixed-effect-model/pll.png" alt="pll" /></p>

<p>The upper panel showed the chains quickly converged to posterior log-likelihoods
near 100th iteration and the right panel confirmed the rhat value (&lt; 1.1).</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>p2 &lt;- plot(fit, pll = FALSE, den= FALSE)
p3 &lt;- plot(fit, pll = FALSE, den= TRUE)
png("den.png", 800, 600)
gridExtra::grid.arrange(p2, p3, ncol = 1)
dev.off()

</code></pre></div></div>

<p><img src="/images/fixed-effect-model/den.png" alt="den" /></p>

<p>In a simulation study, we can check whether the sampling process is OK,
using <em>summary</em></p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>est &lt;- summary(fit, recover = TRUE, ps = p.vector, verbose = TRUE)
##                   a   sv    sz   t0    v     z
## True           1.00 0.20  0.25 0.15 1.20  0.38
## 2.5% Estimate  0.99 0.02  0.01 0.14 1.09  0.32
## 50% Estimate   1.07 0.41  0.22 0.15 1.45  0.35
## 97.5% Estimate 1.16 1.18  0.43 0.16 1.81  0.39
## Median-True    0.07 0.21 -0.03 0.00 0.25 -0.03
</code></pre></div></div>

<p>Finally, we may want to check whether the model fits the data
well.  There are many methods to to quantify the goodness of fit.
Here, I illustrate two methods. First method is to calculate DIC
and BPIC. These information criteria are useful for model selection. 
(need &gt; ggdmc 2.5.5)</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>DIC(fit)
BPIC(fit)
</code></pre></div></div>

<p>Secondly, I simulate post-predictive data, based on the parameter estimates.
<em>xlim</em> trims off outlier values in the simulation data.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pp &lt;- predict_one(fit, xlim = c(0, 5))
dat$C &lt;- ifelse(dat$S == "s1"  &amp; dat$R == "r1",  TRUE,
         ifelse(dat$S == "s2" &amp; dat$R == "r2", TRUE,
         ifelse(dat$S == "s1"  &amp; dat$R == "r2", FALSE,
         ifelse(dat$S == "s2" &amp; dat$R == "r1",  FALSE, NA))))
pp$C &lt;- ifelse(pp$S == "s1"  &amp; pp$R == "r1",  TRUE,
        ifelse(pp$S == "s2" &amp; pp$R == "r2", TRUE,
        ifelse(pp$S == "s1"  &amp; pp$R == "r2", FALSE,
        ifelse(pp$S == "s2" &amp; pp$R == "r1",  FALSE, NA))))

dat$reps &lt;- NA
dat$type &lt;- "Data"
pp$reps &lt;- factor(pp$reps)
pp$type &lt;- "Simulation"

DT &lt;- rbind(dat, pp)
p1 &lt;- ggplot(DT, aes(RT, color = reps, size = type)) +
  geom_freqpoly(binwidth = .05) +
  scale_size_manual(values = c(1, .3)) +
  scale_color_grey(na.value = "black") +
  theme(legend.position = "none") +
  facet_grid(S ~ C)


d &lt;- data.table::data.table(dat)
d[, .N, .(S, R)]
##     S  R  N
## 1: s1 r1 87
## 2: s1 r2 13
## 3: s2 r1 34
## 4: s2 r2 66
</code></pre></div></div>
<p><img src="/images/fixed-effect-model/post-predictive.png" alt="post-predictive" /></p>

<p>The grey lines are model predictions. By default, predict_one randomly draws 100
parameter estimates and simulate data based on them.  Therefore, there are 100 
lines, showing the prediction variability. The solid dark line is
the data, in the case, appropriately fall within the range covering by the grey lines.
Note that the error responses (FALSE) are not predicted as well as the correct responses.
This is fairly common, when the number of trial is minimal. In this case, it has only
13 trials.</p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>This is often dubbed, drift-diffusion model, but in Ratcliff and McKoon’s work, they called it diffusion decision model. <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>

			</article>
		</section>

		<script>
			document.getElementById("open-nav").addEventListener("click", function () {
				document.body.classList.toggle("nav-open");
			});

			
		</script>

		  
		</script>
	</body>
</html>
